# Программирование многопоточных приложений с помощью POSIX Threads

## Цель работы

+ Освоить разработку многопоточных программ с использованием `POSIX Threads API`.
+ Познакомиться с задачей динамического распределения работы между процессорами.

## Формулировка задачи

Есть список неделимых заданий, каждое из которых может быть выполнено независимо от другого.
Необходимо организовать параллельную обработку заданий на нескольких компьютерах.

## Сложность задачи

Сложность задачи заключается в:

+ разработке правильной политики взаимодействия между процессами, когда все посылки запросов и данных и ожидания приема запросов и данных будут согласованы;
+ организации корректной работы многих потоков с общими структурами данных. Необходимо обеспечивать взаимное исключение потоков при добавлении заданий в список, удалении задач, выборке заданий для выполнения. Кроме того, надо помнить, что могут быть некоторые неявно используемые обшие данные, в частности, сокрытые в реализации подключаемых библиотек и в том числе `MPI`.

## Инструменты

+ Для организации взаимодействия между компьютерами использовать `MPI`.
+ Для организации потоков использовать `POSIX Threads`.

## Формирование списка заданий

Задание в данном случае пусть будет иметь совершенно модельный характер. Например, оно может быть таким: выполнить некоторые тратящие время процессора действия `repeatNum` раз. Различие в вычислительном весе заданий будет заключаться в том, что у каждого задания количество повторений `repeatNum` свое:

```C
    TaskList taskList;
    double globalRes = 0;
    int iterCounter = 0;

    ...

    // Итерации обработки списков
    while(true) {
        // Счетчик глобальных итераций
        iterCounter++;

        // Выборка заданий из списка
        for(Task task : taskList) 
            for(int i = 0; i < task.repeatNum; i++)
                globalRes += sqrt(i);
        
        ...

    }
```

Вес задачи можно назначить случайным образом с использованием функции `rand()`, однако для экспериментов лучше задать некоторые осмысленные правила изменения загрузки на процессорах.
Например, на каждой глобальной итерации `iterCounter` веса заданий на процессоре с номером `rank` установить пропорционально `abs(rank-(iterCounter%size))`, где `size` - количество процессоров.
Это создаст "волну" загрузки, смещающуюся с ходом итераций от процессора с меньшим номером к процессору с большим номером (с перескакиванием на начало).

## Требования к реализации

+ Задания могут иметь различный вычислительный вес, т.е. требовать при одних и тех же вычислительных ресурсах различного времени для выполнения;
+ Считается, что вес задания нельзя узнать, пока оно не выполнено;
+ После того, как все задания из списка выполнены, появляется новый список заданий;
+ Количество заданий существенно превосходит количество процессоров;
+ Программа не должна зависеть от числа компьютеров;

## Рекомендации

1. Понятно, что для распараллеливания задачи задания из списка нужно распределять между компьютерами.
Так как задания имеют различный вычислительный вес, а список обрабатывается итеративно, и требуется синхронизация перед каждой итерацией, то могут возникать ситуации, когда некоторые процессоры выполнили свою работу, а другие - еще нет.
Если ничего не предпринять, первые будут простаивать в ожидании последних.
Так возникает задача динамического распределения работы.
Для ее решения на каждом процессоре заведем несколько потоков.
Как минимум, потоков должно быть 2:

    + Поток, который обрабатывает задания и, когда задания закончились, обращается к другим компьютерам за добавкой к работе;
    + Поток, ожидающий запросов о работе от других компьютеров;

    Полезно может быть завести третий поток, который возьмет на себя задачу подкачки работ на компьютер, при этом первый поток будет только обрабатывать задания.
    В таком случае третий поток, до того как кончатся задания (соответствующий момент времени определить самостоятельно), на фоне счета будет отсылать запросы о работе и добавлять к локальному списку пришедшие задания.

2. Для посылки запросов и данных к конкретным адресатам можно использовать, как обычно, `MPI_Send` с указанием номера процесса-адресата.
Для приема запроса от любого процесса можно использовать функцию `MPI_Recv`, где в качестве параметра "источник сообщения" указать константу `MPI_ANY_SOURCE`.
